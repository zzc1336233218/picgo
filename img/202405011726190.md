# Kafka消息中间件

## 1.Kafka介绍

### 1.1 What is Kafka？

- 官网： https://kafka.apache.org/
- 超过 80% 的财富 100 强公司信任并使用 Kafka ；
-  Apache Kafka 是一个开源分布式事件流平台，被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用程序；

### 1.2 谁在使用Kafka？

![image-20240410151026696](C:/Users/ZZC/AppData/Roaming/Typora/typora-user-images/image-20240410151026696.png)

### 1.3 Kafka的起源

- kafka 最初由 LinkedIn （领英：全球最大的面向职场人士的社交网站）设计开发的，是为了解决 LinkedIn 的数据管道问题，用于 LinkedIn 网站的活动流数据和运营数据处理工具；

  - 活动流数据：页面访问量、被查看页面内容方面的信息以及搜索情况等内容；

  - 运营数据：服务器的性能数据（ CPU 、 IO 使用率、请求时间、服务日志等数据 ) ；

- 刚开始 LinkedIn 采用的是 ActiveMQ 来进行数据交换，大约在 2010 年前后，那时的ActiveMQ 还远远无法满足 LinkedIn 对数据交换传输的要求，经常由于各种缺陷而导致消息阻塞或者服务无法正常访问，为了解决这个问题， LinkedIn 决定研发自己的消息传递系统，当时 LinkedIn 的首席架构师 jay kreps 便开始组织团队进行消息传递系统的研发；

### 1.4 Kafka名字的由来

- 由于 Kafka 的架构师 jay kreps 非常喜欢 franz kafka ( 弗兰茨 · 卡夫卡 ) （是奥匈帝国一位使用德语的小说家和短篇犹太人故事家，被评论家们认为是 20 世纪作家中最具影响力的一位） , 并且觉得 Kafka 这个名字很酷，因此把这一款消息传递系统取名为 Kafka ；
- 大师门取名字也是根据自己的喜好来取名，在我们看来有可能感觉很随意！

### 1.5 Kafka的发展历史

> 2010 年底， Kafka 在 Github 上开源，初始版本为 0.7.0 ；
> 2011 年 7 月，因为备受关注，被纳入 Apache 孵化器项目；
> 2012 年 10 月， Kafka 从 Apache 孵化器项目毕业，成为 Apache 顶级项目；
> 2014 年， jay kreps 离开 LinkedIn ，成立 confluent 公司，此后 LinkedIn 和 confluent成为 kafka 的核心代码贡献组织，致力于 Kafka 的版本迭代升级和推广应用；

### 1.6 Kafka版本迭代

> Kafka 前期项目版本似乎有点凌乱， Kafka 在 1.x 之前的版本，是采用 4 位版本号；
> 比如： 0.8.2.2 、 0.9.0.1 、 0.10.0.0... 等等；
> 在 1.x 之后， kafka 采用 Major.Minor.Patch 三位版本号；
> Major 表示大版本，通常是一些重大改变，因此彼此之间功能可能会不兼容；
> Minor 表示小版本，通常是一些新功能的增加；
> Patch 表示修订版，主要为修复一些重点 Bug 而发布的版本 ;
> 比如： Kafka 2.1.3 ，大版本就是 2 ，小版本是 1 ， Patch 版本为 3 ，是为修复 Bug 发布的第 3 个版本；
> Kafka 总共发布了 8 个大版本，分别是 0.7.x 、 0.8.x 、 0.9.x 、 0.10.x 、 0.11.x 、 1.x 、 2.x 及 3.x版本，截止目前，最新版本是 Kafka 3.7.0 ，也是最新稳定版本；

## 2.Kafka安装

### 2.1 Kafka运行环境前置要求

> Kafka 是由 Scala 语言编写而成， Scala 运行在 Java 虚拟机上，并兼容现有的 Java 程序，因此部署 Kakfa 的时候，需要先安装 JDK 环境；
> Kafka 源码 : https://github.com/apache/kafka
> Scala 官网： https://www.scala-lang.org/
> 本地环境必须安装了 Java 8+ ；（ Java8 、 Java11 、 Java17 、 Java21 都可以）；
> JDK 长期支持版： https://www.oracle.com/java/technologies/java-se-support-roadmap.html

### 2.2 Kafka运行环境jdk安装

1. 下载 JDK ： https://www.oracle.com/java/technologies/downloads/#java17

   ![image-20240410151915528](C:/Users/ZZC/AppData/Roaming/Typora/typora-user-images/image-20240410151915528.png)

2. 解压缩： tar -zxvf jdk-17_linux-x64_bin.tar.gz -C /usr/local

   切换到/usr/local目录下

   ![image-20240410165158656](C:/Users/ZZC/AppData/Roaming/Typora/typora-user-images/image-20240410165158656.png)

3. 配置 JDK 环境变量：

   1. vim /etc/profile

      ```tex
      export JAVA_HOME=/usr/local/jdk-17.0.10
      export PATH=$JAVA_HOME/bin:$PATH
      export CLASSPATH=.:$JAVA_HOME/lib/
      ```

    2. 使用source命令对修改的配置进行生效

       ```tex
       source /etc/profile
       ```

    3. 查看java版本

       ![image-20240410172431853](C:/Users/ZZC/AppData/Roaming/Typora/typora-user-images/image-20240410172431853.png)

   

### 2.3 Kafka的下载和安装

- 获取Kafka

  - 下载最新版本的 Kafka ： https://kafka.apache.org/downloads

  ![image-20240410172959662](C:/Users/ZZC/AppData/Roaming/Typora/typora-user-images/image-20240410172959662.png)

- 安装Kafka

  - tar -xzf kafka_2.13-3.7.0.tgz -C /usr/local/
  - cd /usr/local/kafka_2.13-3.7.0



- 启动运行Kafka
  - 启动 Kafka 环境
    	注意：本地环境必须安装了 Java 8+ ；
    	Apache Kafka 可以使用 ZooKeeper 或 KRaft 启动；但只能使用其中一种方式，不能同时使用；
    	KRaft ： Apache Kafka 的内置共识机制，用于取代 Apache ZooKeeper ；
  - Kafka 启动使用 Zookeeper  &表示后台运行
    	1 、启动 zookeeper ： ./zookeeper-server-start.sh ../config/zookeeper.properties &
    	2 、启动 kafka ： ./kafka-server-start.sh ../config/server.properties &
    	3 、关闭 Kafka ： ./kafka-server-stop.sh ../config/server.properties
    	4 、关闭 zookeeper: ./zookeeper-server-stop.sh ../config/zookeeper.properties



### 2.4 Zookeeper的下载和安装

#### 2.4.1 获取zookeeper

**下载最新版本的 Zookeeper ： https://zookeeper.apache.org/**

![image-20240411102647305](assets/image-20240411102647305.png)**安装 Zookeeper**

将下载的zookeeper传输到linux中

![image-20240411103223869](assets/image-20240411103223869.png)

**将zookeeper解压到/usr/local目录下**

tar -xzf apache-zookeeper-3.9.2-bin.tar.gz -C /usr/local/

cd apache-zookeeper-3.9.2-bin



#### 2.4.2 Zookeeper的配置和启动

- 配置Zookeeper 到conf目录中复制配置文件

  - cp zoo_sample.cfg zoo.cfg
  - zoo.cfg 不需要修改，直接使用即可

- 启动Zookeeper

  - 启动：zkServer.sh start

    ![image-20240411104726967](assets/image-20240411104726967.png)

    发现zookeeper启动会占用3个端口

    ![image-20240411105424444](assets/image-20240411105424444.png)

  - 关闭：zkServer.sh stop

  - zookeeper启动默认会占用8080端口，修改配置文件，添加如下配置

    cd conf

    vim zoof.cfg

    admin.serverPort=9089

    重启zookeeper

    ![image-20240411105943941](assets/image-20240411105943941.png)

#### 2.4.3 使用独立的zookeeper启动Kafka

1. 启动zookeeper

   - zkServer.sh start

2. 启动Kafka

   - ./kafka-server-start.sh ../config/server.properties &

     ![image-20240411110609208](assets/image-20240411110609208.png)

### 2.4 使用KRaft启动运行Kafka

#### 2.4.1 Kafka启动使用KRaft

- 生成Cluster UUID（集群UUID）： ./kafka-storage.sh random-uuid

  ![image-20240411112508312](assets/image-20240411112508312.png)

  ​	每次返回的uuid不一样

  ![image-20240411135129426](assets/image-20240411135129426.png)

- 格式化日志目录： ./kafka-storage.sh format -t sYhr2IwpRGisfAtnHTaSrg -c ../config/kraft/server.properties（-t 后面是uuid）
- 启动Kafka（先将kafka和zookeeper服务停止）：./kafka-server-start.sh ../config/kraft/server.properties &
- 关闭Kafka：./kafka-server-stop.sh ../config/kraft/server.properties



### 2.5 使用docker启动运行Kafka

#### 2.5.1 docker安装

> 安装前查看系统是否已经安装了 Docker ：
> 	yum list installed | grep docker
> 卸载 Docker(-y参数 自动确认的意思  remove后面是已安装列表中的名字) ：
> 	yum remove docker.x86_64 -y
> 	yum remove docker-client.x86_64 -y
> 	yum remove docker-common.x86_64 -y
> 安装 Docker ：
> 	yum install docker -y
> 	注：这种方式安装的 Docker 版本比较旧；（查看版本： docker -v ）

![image-20240411142545316](assets/image-20240411142545316.png)

> 安装最新版的 Docker(须先删除老版docker) ：
> 	1 、 yum install yum-utils -y
> 	2 、 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
> 	3 、 yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y
> 查看是否安装成功：
> 查看 docker 版本： docker --version （ docker version ， docker -v ）

![image-20240411142444280](assets/image-20240411142444280.png)

#### 2.5.2 docker启动

> ​	启动： systemctl start docker 或者 service docker start
> ​	停止： systemctl stop docker 或者 service docker stop
> ​	重启： systemctl restart docker 或者 service docker restart
> ​	检查 Docker 进程的运行状态： systemctl status docker 或者 service docker status
> ​	查看 docker 进程： ps -ef | grep docker
> ​	查看 docker 系统信息： docker info
> ​	查看所有的帮助信息： docker --help
> ​	查看某个 commond 命令的帮助信息： docker commond --help

> 使用 Docker 镜像启动
> 	1 、拉取 Kafka 镜像： docker pull apache/kafka:3.7.0
> 	2 、启动 Kafka 容器(须先把虚拟机的Kafka停止)： docker run -p 9092:9092 apache/kafka:3.7.0
> 	查看已安装的镜像： docker images
> 	删除镜像： docker rmi apache/kafka:3.7.0



## 3.Kafka操作

### 3.1 创建主题Topic

#### 3.1.1 使用Kafka之前，第一件事情是必须创建一个主题（topic）

- 主题（Topic）类似于文件系统中的文件夹；

- 主题（Topic）用于存储事件（Events）

  - 事件（Events）
  - 也称为记录或消息，比如支付交易、手机地理位置更新、运输订单、物联网设备或医疗设备的传感器测量数据等等都是事件（ Events ）；
  - 事件（ Events ）被组织和存储在主题（ Topic ）中
  - 简单来说，主题（ Topic ）类似于文件系统中的文件夹，事件（ Events ）是该文件夹中的文件；

- 创建主题使用：kafka-topics.sh脚本；

  - 不带任何参数回告知该脚本如何使用：./kafka-topics.sh

  - 创建主题：./kafka-topics.sh --create --topic hello --bootstrap-server localhost:9092

    ![image-20240411162234265](assets/image-20240411162234265.png)

  - 列出所有的主题：./kafka-topics.sh --list --bootstrap-server localhost:9092

    ![image-20240411162333910](assets/image-20240411162333910.png)

  - 删除主题：./kafka-topics.sh --delete --topic hello --bootstrap-server localhost:9092

  - 显示主题详细信息：./kafka-topics.sh --describe --topic hello --bootstrap-server localhost:9092

    ![image-20240411162713387](assets/image-20240411162713387.png)exec

  - 修改主题信息：./kafka-topics.sh --alter --topic hello --partitions 3 --bootstrap-server localhost:9092

    ![image-20240411165459221](assets/image-20240411165459221.png)

    

### 3.2 在主题（Topic）中写入一些事件(Events)

- Kafka客户端通过网络与Kafka Brokers进行通信，可以写（或读）主题Topic中的事件Events;

  ![image-20240411170444017](assets/image-20240411170444017.png)

- Kafka brokers一旦受到事件Event，

- 就会将事件 Event 以持久和容错的方式存储起来，可以永久地
  存储；

- 通过 kafka-console-producer.sh 脚本工具写入事件 Events ；

  - 不带任何参数会告知该脚本如何使用： ./kafka-console-producer.sh
  - ./kafka-console-producer.sh --topic hello --bootstrap-server localhost:9092
  - 每一次换行是一个事件 Event ；
  - 使用 Ctrl+C 退出，停止发送事件 Event 到主题 Topic ；

  ![image-20240411173635878](assets/image-20240411173635878.png)

### 3.3 从主题（Topic）中读取事件（Events）

![image-20240411173437446](assets/image-20240411173437446.png)

- 使用 kafka-console-consumer.sh 消费者客户端读取之前写入的事件 Event ：
  - 不带任何参数会告知该脚本如何使用： ./kafka-console-consumer.sh
  - ./kafka-console-consumer.sh --topic hello --from-beginning --bootstrap-server localhost:9092
  - --from-beginning 表示从 kafka 最早的消息开始消费 不加表示读取最新消息
  - 使用 Ctrl+C 停止消费者客户端；
- 事件 Events 是持久存储在 Kafka 中的，所以它们可以被任意多次读取；

![image-20240411173646357](assets/image-20240411173646357.png)



### 3.4 外部环境连接Kafka

1. 启动 Kafka 容器： docker run -p 9092:9092 apache/kafka:3.7.0 &
2. 安装外部连接工具；
3. 外部连接工具连接 Kafka ；

![image-20240412093047903](assets/image-20240412093047903.png)

#### 3.4.1 外部环境无法连接Kafka

##### 3.4.1.1 复制docker中kafka的配置文件到linux中

-  文件输入：提供一个本地 kafka 属性配置文件，替换 docker 容器中的默认配置文件；
- cd /usr/local
- mkdir docker
- docker ps
- docker run -p 9092:9092 apache/kafka:3.7.0
- docker exec -it 容器 id /bin/bash
- 把 docker 容器中的文件复制到 linux 中：
  - docker cp 容器id:/etc/kafka/docker/server.properties /user/local/docker

![image-20240412094058451](assets/image-20240412094058451.png)

##### 3.4.1.2 修改linux的配置文件和文件映射

- 配置文件： server.properties
- listeners=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
- advertised.listeners=PLAINTEXT://虚拟机ip:9092
  - advertise 的含义表示宣称的、公布的， Kafka 服务对外开放的 IP 和端口 ;
- 文件映射： docker run --volume /usr/local/kafka_2.13-3.7.0/docker:/mnt/shared/config -p 9092:9092 apache/kafka:3.7.0

##### 3.4.1.3 测试连接

创建topic

```shell
./kafka-topics.sh --create --topic hello --bootstrap-server localhost:9092
```

idea使用kafka插件进行连接

![image-20240412140530524](assets/image-20240412140530524.png)

### 3.5 Kafka图形界面连接工具

- Kafka 图形界面连接工具：
  - Offset Explorer ( 以前叫 Kafka Tool) ，官网： https://www.kafkatool.com/
  - CMAK （以前叫 Kafka Manager ） 官网： https://github.com/yahoo/CMAK
  - EFAK （以前叫 kafka-eagle ） 官网： https://www.kafka-eagle.org/

#### 3.5.1 CMAK（以前叫 Kafka Manager ）

- 一个 web 后台管理系统，可以管理 kafka ；
- 项目地址： https://github.com/yahoo/CMAK
- 注意该管控台运行需要 JDK11 版本的支持；
- 下载： https://github.com/yahoo/CMAK/releases
- 下载下来是一个 zip 压缩包，直接 unzip 解压：
- unzip cmak-3.0.0.6.zip
- 解压后即完成了安装；

- 基于 zookeeper 方式启动 kafka 才可以使用该 web 管理后台，否则不行；
  - 1 、 CMAK 配置：
    - 修改 conf 目录下的 application.conf 配置文件：
    - kafka-manager.zkhosts="192.168.11.128:2181"
    - cmak.zkhosts="192.168.11.128:2181"
  - 2 、 CMAK 启动：
    - 切换到 bin 目录下执行：
    - ./cmak -Dconfig.file=../conf/application.conf -java-home /usr/local/jdk-11.0.22
    - 其中 -Dconfig.file 是指定配置文件， -java-home 是指定 jdk11 所在位置，如果机器上已经是 jdk11 ，则不需要指定；
  - 3 、 CMAK 访问：
    - 启动之后 CMAK 默认端口为 9000 ，访问： http://192.168.11.128:9000/

#### 3.5.2 EFAK （以前叫 kafka-eagle ）

- EFAK 一款优秀的开源免费的 Kafka 集群监控工具；（国人开发并开源）
  - 官网： https://www.kafka-eagle.org/
  - Github ： https://github.com/smartloli/EFAK
- EFAK 下载与安装：
  - 下载： https://github.com/smartloli/kafka-eagle-bin/archive/v3.0.1.tar.gz
  - 安装，需要解压两次：
    1. tar -zxvf kafka-eagle-bin-3.0.1.tar.gz
    2. cd kafka-eagle-bin-3.0.1
    3. tar -zxvf efak-web-3.0.1-bin.tar.gz
    4. cd efak-web-3.0.1

## 4.SpringBoot集成Kafka开发

### 4.1 创建项目

![image-20240412134915681](assets/image-20240412134915681.png)

![image-20240412134938258](assets/image-20240412134938258.png)

### 4.2 配置文件

application.yml

```yaml
spring:
  application:
    name: spring-boot-01-kafka-base

  kafka:
    bootstrap-servers: 192.168.2.118:9092
```

![image-20240412142633546](assets/image-20240412142633546.png)

### 4.3 创建生产者

```java
package com.zzc.producer;

import jakarta.annotation.Resource;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

@Component
public class EventProducer {

    @Resource
    private KafkaTemplate<String, String> kafkaTemplate;

    public void sendEvent(){
        kafkaTemplate.send("hello-topic", "hello kafka");
    }
}
```



### 4.4 测试

```java
package com.zzc.producer;

import jakarta.annotation.Resource;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

@Component
public class EventProducer {

    @Resource
    private KafkaTemplate<String, String> kafkaTemplate;

    public void sendEvent(){
        kafkaTemplate.send("hello-topic", "hello kafka");
    }
}

```

hello-topic中已存放一个消息

![image-20240412144527136](assets/image-20240412144527136.png)



### 4.5 创建消费者

```java
package com.zzc.cosumer;

import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

@Component
public class EventConsumer {

    // 采用监听的方式接收事件（消息、数据）
    @KafkaListener(topics = {"hello-topic"}, groupId = "hello-group")
    public void onEvent(String event){
        System.out.printf("读取到的事件：" + event);
    }
}
```

启动springboot，发现并没有读取到之前的消息

![image-20240412150416720](assets/image-20240412150416720.png)

此时使用测试类调用生成者再发送一个消息，此时消费者成功监听到刚生产的消息

![image-20240412150604078](assets/image-20240412150604078.png)

### 4.6 Kafka的几个概念

![image-20240412153614944](assets/image-20240412153614944.png)

![image-20240412153648495](assets/image-20240412153648495.png)

- 默认情况下，当启动一个新的消费者组时，它会从每个分区的最新偏移量（即该分区中最后一条消息的下一个位置）开始消费。如果希望从第一条消息开始消费，需要将消费者的 auto.offset.reset 设置为 earliest ；
- 注意： 如果之前已经用相同的消费者组 ID 消费过该主题，并且 Kafka 已经保存了该消费者组的偏移量，那么即使你设置了 auto.offset.reset=earliest ，该设置也不会生效，因为 Kafka 只会在找不到偏移量时使用这个配置。在这种情况下，你需要手动重置偏移量或使用一个新的消费者组 ID ；

### 4.7 消息消费时偏移量策略的配置

```yaml
 spring:
 	kafka:
 		consumer:
 			auto-offset-reset: earliest
```

- 取值： earliest 、 latest 、 none 、 exception
  - earliest ：自动将偏移量重置为最早的偏移量；
  - latest ：自动将偏移量重置为最新偏移量；
  - none ：如果没有为消费者组找到以前的偏移量，则向消费者抛出异常；
  - exception ：向消费者抛出异常；（ spring-kafka 不支持）

#### 4.7.1 测试修改配置后能否消费之前的消息

修改配置重启服务后，并没有消费之前的消息

![image-20240412154152450](assets/image-20240412154152450.png)

修改消费者组ID，再次重启服务进行测试

```java
@Component
public class EventConsumer {

    // 采用监听的方式接收事件（消息、数据）
    @KafkaListener(topics = {"hello-topic"}, groupId = "hello-group-02")
    public void onEvent(String event){
        System.out.println("读取到的事件：" + event);
    }
}
```

成功读取到之前的消息

![image-20240412154658882](assets/image-20240412154658882.png)



#### 4.7.2 手动重置偏移量

```shell
修改为读取最早的消息
./kafka-consumer-groups.sh --bootstrap-server <your-kafka-bootstrap-servers> --group <your-consumer-group> --topic <your-topic> --reset-offsets --to-earliest --execute

修改为读取最新的消息
./kafka-consumer-groups.sh --bootstrap-server <your-kafka-bootstrap-servers> --group <your-consumer-group> --topic <your-topic> --reset-offsets --to-latest --execute
```

执行命令

```shell
./kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group hello-group-02 --topic hello-topic --reset-offsets --to-earliest --execute
```

![image-20240412160530833](assets/image-20240412160530833.png)

报错：提示我们不能在活跃的情况下进行修改偏移量，需要先停止服务

再次执行命令，已经重置偏移量成功

![image-20240412160637951](assets/image-20240412160637951.png)

此时启动服务，读取到之前的消息了

![image-20240412160718957](assets/image-20240412160718957.png)



### 4.8 生产者发送消息参数（生产者客户端向Kafka的主题topic中写入事件）

![image-20240412162210656](assets/image-20240412162210656.png)

#### 4.8.1 message对象参数

```java
    /**
     * 使用message对象发送消息
     */
    public void sendEvent02(){
        // 通过构建器模式创建Message对象
        Message<String> message = MessageBuilder.withPayload("hello kafka")
                // 在header中放置topic的名字
                .setHeader(KafkaHeaders.TOPIC, "test-topic-02")
                .build();
        kafkaTemplate.send(message);
    }
```

测试是否发送消息到topic中

```java
@Test
public void test02(){
    eventProducer.sendEvent02();
}
```

成功发送消息到test-topic-02中

![image-20240412163012902](assets/image-20240412163012902.png)



#### 4.8.2 producerRecord对象参数

```java
    /**
     * 使用ProducerRecord对象发送消息
     */
    public void sendEvent03(){

        // Headers里面是放一些信息（信息是key-value键值对），到时候消费者接收到该消息后，可以拿到这个Headers里面放的信息
        Headers headers = new RecordHeaders();
        headers.add("phone", "13698001234".getBytes(StandardCharsets.UTF_8));
        headers.add("orderId", "12473289472846178242873".getBytes(StandardCharsets.UTF_8));

        ProducerRecord<String, String> producerRecord = new ProducerRecord<>(
                "test-topic-02",
                0,
                System.currentTimeMillis(),
                "k1",
                "hello kafka",
                headers
        );
        kafkaTemplate.send(producerRecord);
    }
```

测试

```java
@Test
public void test03(){
    eventProducer.sendEvent03();
}
```

成功向test-topic-02中发送一条消息

![image-20240412165047162](assets/image-20240412165047162.png)

#### 4.8.3 send最多参数构造方法

```java
    public void sendEvent04() {
        // String topic, Integer partition, Long timestamp, K key, @Nullable V data
        kafkaTemplate.send(
                "test-topic-02",
                0,
                System.currentTimeMillis(),
                "k2",
                "hello kafka"
        );
    }
```

测试

```java
@Test
public void test04(){
    eventProducer.sendEvent04();
}
```

成功向test-topic-02中发送一条消息

![image-20240412170043199](assets/image-20240412170043199.png)

#### 4.8.4 sendDefault最多参数构造方法

```java
public void sendEvent05(){
    kafkaTemplate.sendDefault(0, System.currentTimeMillis(), "k3", "hello kafka");
}
```

测试

```java
@Test
public void test04(){
    eventProducer.sendEvent04();
}
```

执行测试方法，报错提示 topic不能为空

![image-20240412170908074](assets/image-20240412170908074.png)

需要在配置文件中添加配置

```yaml
spring:
  application:
    name: spring-boot-01-kafka-base

  kafka:
    bootstrap-servers: 192.168.2.118:9092
    consumer:
      auto-offset-reset: earliest
    # 配置模板默认的主题topic名称
    template:
      default-topic: default-topic
```

再次执行测试方法，成功向default-topic中发送消息

![image-20240412171130280](assets/image-20240412171130280.png)

### 4.9 KafkaTemplate.send()和KafkaTemplate.sendDefault()的区别

- 主要区别是发送消息到 Kafka 时是否每次都需要指定主题 topic；
  -  kafkaTemplate.send(...) 该方法需要明确地指定要发送消息的目标主题 topic ；
  - kafkaTemplate.sendDefault() 该方法不需要指定要发送消息的目标主题 topic ；
- kafkaTemplate.send(...) 方法适用于需要根据业务逻辑或外部输入动态确定消息目标 topic 的场景;
- kafkaTemplate.sendDefault() 方法适用于总是需要将消息发送到特定默认 topic 的场景；
- kafkaTemplate.sendDefault() 是一个便捷方法，它使用配置中指定的默认主题 topic 来发送消息；
- 如果应用中所有消息都发送到同一个主题时采用该方法非常方便，可以减少代码的重复或满足特定的业务需求；

### 4.10 获取生产者消息发送结果

- .send() 方法和 .sendDefault() 方法都返回 CompletableFuture<SendResult<K, V>> ；
- CompletableFuture 是 Java 8 中引入的一个类，用于异步编程，它表示一个异步计算的结果，这个特性使得调用者不必等待操作完成就能继续执行其他任务，从而提高了应用程序的响应速度和吞吐量；

- 方式一：调用 CompletableFuture 的 get() 方法，同步阻塞等待发送结果；
- 方式二：使用 thenAccept(), thenApply(), thenRun() 等方法来注册回调函数，回调函数将在CompletableFuture 完成时被执行；

#### 4.10.1 调用 CompletableFuture 的 get() 方法，同步阻塞等待发送结果

```java
 /**
     * 通过get方法同步阻塞等待发送结果
     */
    public void sendEvent06(){
        CompletableFuture<SendResult<String, String>> completableFuture =
                kafkaTemplate.sendDefault(0, System.currentTimeMillis(), "k3", "hello kafka");
        try {
            // 1.阻塞等待的方式拿结果
            SendResult<String, String> sendResult = completableFuture.get();
            if (sendResult.getRecordMetadata() != null){
                // kafka服务器确认已经接收到了消息
                System.out.println("消息发送成功：" + sendResult.getRecordMetadata().toString());
            }
            System.out.println("producerRecord: " + sendResult.getProducerRecord());
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }
```

测试，成功获取到结果和发送的消息信息

```java
@Test
public void test06(){
    eventProducer.sendEvent06();
}
```

![image-20240412174207017](assets/image-20240412174207017.png)



#### 4.10.2 使用 thenAccept()方法来注册回调函数，回调函数将在CompletableFuture 完成时被执行

```java
    /**
     * 通过thenAccept方法注册回调函数
     */
    public void sendEvent07(){
        CompletableFuture<SendResult<String, String>> completableFuture =
                kafkaTemplate.sendDefault(0, System.currentTimeMillis(), "k3", "hello kafka");
        completableFuture.thenAccept(sendResult -> {
            if (sendResult.getRecordMetadata() != null){
                // kafka服务器确认已经接收到了消息
                System.out.println("消息发送成功：" + sendResult.getRecordMetadata().toString());
            }
            System.out.println("producerRecord: " + sendResult.getProducerRecord());
        }).exceptionally( throwable -> {
            // 做失败的处理
            throwable.printStackTrace();
            return null;
        });
    }
```

测试，成功获取到结果和发送的消息信息

```java
@Test
public void test07(){
    eventProducer.sendEvent07();
}
```

![image-20240412175412956](assets/image-20240412175412956.png)



### 4.11 生产者发送对象消息

#### 4.11.1 创建User对象

```java
@Builder
@AllArgsConstructor
@NoArgsConstructor
@Data
public class User {

    private int id;

    private String phone;

    private Date birthDay;
}

```

#### 4.11.2 注入新的kafkaTemplate对象，因为之前的key和value泛型都是String类型

```java
/**
* 发送对象消息
*/
@Resource
private KafkaTemplate<String, Object> kafkaTemplate2;
private KafkaTemplate<String, Object> kafkaTemplate2;
public void sendEvent08(){
    User user = User.builder().id(1200).phone("13698981234").birthDay(new Date()).build();
    // 分区编号为 null ，交给 kafka 自己去分配
    kafkaTemplate2.sendDefault(null, System.currentTimeMillis(), "k4", user);
}
```

#### 4.11.3 测试发送消息

报错 说不能将value转成StringSerializer

![image-20240413113629362](assets/image-20240413113629362.png)

需要在配置文件中指定value的Serializer类型

```yaml
    producer:
      # key和value都默认是StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
```

再次执行测试，执行成功

![image-20240413114039048](assets/image-20240413114039048.png)

defalut-topic中新增一条消息

![image-20240413114140411](assets/image-20240413114140411.png)



### 4.12 Kafka的核心概念：Replica副本

- Replica ：副本，为实现备份功能，保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且
  Kafka 仍然能够继续工作， Kafka 提供了副本机制，一个 topic 的每个分区都有 1 个或多个副本；
- Replica 副本分为 Leader Replica 和 Follower Replica ：
  - Leader ：每个分区多个副本中的“主”副本，生产者发送数据以及消费者消费数据，都是来自 leader 副本
  - Follower ：每个分区多个副本中的“从”副本，实时从 leader 副本中同步数据，保持和 leader 副本数据的同
    步， leader 副本发生故障时，某个 follower 副本会成为新的 leader 副本；
- **设置副本个数不能为 0 ，也不能大于节点个数，否则将不能创建 Topic ；**



#### 4.12.1 指定topic的分区和副本

##### 4.12.1.1 方式一：通过Kafka提供的命令行工具在创建topic时指定分区和副本

```shell
./kafka-topics.sh --create --topic myTopic --partitions 3 --replication-factor 1 --bootstrap-server 127.0.0.1:9092
```

创建成功

![image-20240414160009912](assets/image-20240414160009912.png)



##### 4.12.1.2 方式二：执行代码时指定分区和副本

- kafkaTemplate.send("topic", message);
- 直接使用 send() 方法发送消息时， kafka 会帮我们自动完成 topic 的创建工作，但这种情况下创建的 topic 默认只有一个分区，分区有 1 个副本，也就是有它自己本身的副本，没有额外的副本备份；
- 我们可以在项目中新建一个配置类专门用来初始化 topic ；

```java
@Configuration
public class KafkaConfig {
	
    // 创建一个名为helloTopic的Topic并设置分区数为5，分区副本数为1
    @Bean
    public NewTopic newTopic(){
        // 副本不能设置为0 也不能超过节点数
        return new NewTopic("helloTopic", 5, (short) 1);
    }
}
```

创建成功

![image-20240414160531222](assets/image-20240414160531222.png)

####  4.12.2 测试重启服务会不会重置消息，先向helloTopic中发送一个消息

```java
    public void sendEvent09(){
        User user = User.builder().id(1200).phone("13698981234").birthDay(new Date()).build();
        kafkaTemplate2.send(
                "helloTopic",
                null,
                System.currentTimeMillis(),
                "k9",
                user
        );    
    }
```

测试代码

```java
@Test
public void test09(){
    eventProducer.sendEvent09();
}
```

成功向helloTopic中发送一个消息

![image-20240414160825172](assets/image-20240414160825172.png)

重启服务后，并没有重置消息

![image-20240414160917238](assets/image-20240414160917238.png)

#### 4.12.3 修改分区数

配置类中增加更新配置代码

```java
@Configuration
public class KafkaConfig {
    
    // 创建一个名为helloTopic的Topic并设置分区数为5，分区副本数为1
    @Bean
    public NewTopic newTopic(){
        return new NewTopic("helloTopic", 5, (short) 1);
    }
    
    // 如果要修改分区数，只需修改配置值重启项目即可，修改分区数并不会导致数据的丢失，但是分区数只能增大不能减少
    @Bean
    public NewTopic updateTopic(){
        return new NewTopic("helloTopic", 10, (short) 1);
    }
}

```

重启项目，分区数更新为10，消息的位置也没发生变化

![image-20240414161401221](assets/image-20240414161401221.png)



#### 4.13 生产者发送消息的分区策略（消息发到哪个分区中？是什么策略）

- 生产者写入消息到topic，Kafka将依据不同的策略将数据分配到不同的分区中

​	如果指定了分区，那将发送消息到指定分区中

![image-20240414162554843](assets/image-20240414162554843.png)

执行测试代码

![image-20240414162624068](assets/image-20240414162624068.png)

看send方法源代码可以看到

![image-20240414163104379](assets/image-20240414163104379.png)



1. 默认分配策略：BuiltInPartitioner
   - 有key：Utils.toPositive(Utils.murmur2(serializedKey)) % numPartitions;
   - 没有key：使用随机数 % numPartitions
2. 轮询分配策略：RoundRobinPartitioner（实现的接口：Partitioner）
3. 自定义分配策略：我们自己定义

##### 4.13.1 轮询分配策略

yml配置文件

```yaml
spring:
  application:
    name: spring-boot-01-kafka-base

  kafka:
    bootstrap-servers: 192.168.2.118:9092
    producer:
      # key和value都默认是StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      auto-offset-reset: earliest
    # 配置模板默认的主题topic名称
    template:
      default-topic: default-topic
```

配置类

```java
package com.zzc.config;

import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.RoundRobinPartitioner;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Value("${spring.kafka.producer.value-serializer}")
    private String valueSerializer;

    @Value("${spring.kafka.producer.key-serializer}")
    private String keySerializer;

    /**
     * 生产者相关配置
     * @return
     */
    public Map<String, Object> producerConfigs(){
        HashMap<String, Object> props = new HashMap<>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, keySerializer);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, valueSerializer);
        props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, RoundRobinPartitioner.class);
        return props;
    }

    public ProducerFactory<String, Object> producerFactory(){
        return new DefaultKafkaProducerFactory<>(producerConfigs());
    }

    /**
     * KafkaTemplate 覆盖相关配置类中的kafkaTemplate
     * @return
     */
    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate(){
        return new KafkaTemplate<>(producerFactory());
    }

    // 创建一个名为helloTopic的Topic并设置分区数为5，分区副本数为1
    @Bean
    public NewTopic newTopic(){
        return new NewTopic("helloTopic", 5, (short) 1);
    }

    // 如果要修改分区数，只需修改配置值重启项目即可，修改分区数并不会导致数据的丢失，但是分区数只能增大不能减少
    @Bean
    public NewTopic updateTopic(){
        return new NewTopic("helloTopic", 10, (short) 1);
    }
}

```

执行测试代码

```java
public void sendEvent09(){
    User user = User.builder().id(1200).phone("13698981234").birthDay(new Date()).build();
    kafkaTemplate2.send(
        "helloTopic",
        user
    );    }
```

```java
@Test
public void test09(){
    for (int i = 0; i < 5; i++) {
        eventProducer.sendEvent09();
    }
}
```

debug模式，是进入到RoundRobinPartitioner类中

![image-20240414174529154](assets/image-20240414174529154.png)

查看消息的分区情况，发现并没有完全的轮询，有点误差

![image-20240414174640886](assets/image-20240414174640886.png)

##### 4.13.2 自定义分配策略

创建自定义分配策略类实现Partitioner接口

```java
public class CustomerPartitioner implements Partitioner {
    
    private AtomicInteger nextPartition = new AtomicInteger(0);
    
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] bytes1, Cluster cluster) {
        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();
        
        if (key == null){
            // 使用轮询方式选择分区
            int next = nextPartition.getAndIncrement();
            // 如果next大于分区的大小，则重置为0
            if (next >= numPartitions){
                nextPartition.compareAndSet(next, 0);
            }
            System.out.println("分区值：" + next);
            return next;
        }else {
            // 如果key不为null，则使用默认的分区策略
            return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
        }
    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> map) {

    }
}
```

配置类代码中将分配策略修改为自定义分配策略

![image-20240414180227259](assets/image-20240414180227259.png)



使用debug模式执行测试代码，成功执行到我们自定义的分配策略类中

![image-20240414180626495](assets/image-20240414180626495.png)

执行结果

![image-20240414180706622](assets/image-20240414180706622.png)

为什么是每隔一个存一个分区呢？查看源代码发现进行了二次计算partition

![image-20240414181011269](assets/image-20240414181011269.png)



### 4.13 生产者发送消息的流程

![image-20240414190729382](assets/image-20240414190729382.png)

#### 4.13.自定义拦截器拦截消息的发送

实现ProducerInterceptor接口，创建CustomerProducerInterceptor类

```java
package com.zzc.config;

import org.apache.kafka.clients.producer.ProducerInterceptor;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

import java.util.Map;

public class CustomerProducerInterceptor implements ProducerInterceptor<String, Object> {
    /**
     * 发送消息时，会先调用该方法，对信息进行拦截，可以在拦截中对消息做一些处理，记录日志等操作...
     * @param producerRecord
     * @return
     */
    @Override
    public ProducerRecord<String, Object> onSend(ProducerRecord<String, Object> producerRecord) {
        System.out.println("拦截消息：" + producerRecord.toString());
        return producerRecord;
    }

    /**
     * 服务器收到消息后的一个确认
     * @param recordMetadata
     * @param e
     */
    @Override
    public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) {
        if (recordMetadata != null){
            System.out.println("服务器收到该消息：" + recordMetadata.offset());
        }else {
            System.out.println("消息发送失败了，exception = " + e.getMessage());
        }
    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> map) {

    }
}

```

配置类中添加拦截器

![image-20240414190902436](assets/image-20240414190902436.png)

执行测试，发现报错了

![image-20240414190928576](assets/image-20240414190928576.png)

需要配置类中添加拦截器的名字

![image-20240414195200071](assets/image-20240414195200071.png)

再次执行测试，成功执行了

![image-20240414195234487](assets/image-20240414195234487.png)



### 4.14 获取生产者发送的消息

之前模块内容比较多，重新创建一个模块

![image-20240414224833914](assets/image-20240414224833914.png)

![image-20240414224924100](assets/image-20240414224924100.png)

消费者类

```java
@Component
public class EventConsumer {

    // 采用监听的方式接收事件（消息、数据）
    @KafkaListener(topics = {"helloTopic"}, groupId = "helloGroup")
    public void onEvent(String event){
        System.out.println("读取到的事件：" + event);
    }
}

```

生产者类

```java
@Component
public class EventProducer {

    @Resource
    private KafkaTemplate<String, String> kafkaTemplate;

    public void sendEvent() {
        kafkaTemplate.send("helloTopic", "hello kafka");
    }
}
```

配置文件

```yaml
spring:
  application:
    name: spring-boot-02-kafka-base

  kafka:
    bootstrap-servers: 192.168.2.118:9092

```

测试代码

```java
@SpringBootTest
class KafkaBaseApplicationTests {

    @Resource
    private EventProducer eventProducer;

    @Test
    void test01(){
        System.out.println(111);
        eventProducer.sendEvent();
    }

}
```

启动服务，执行测试代码，成功读取到最新发送的消息

![image-20240414233158677](assets/image-20240414233158677.png)

#### 4.14.1 @Payload : 标记该参数是消息体内容

消费者类参数添加@Payload注解

![image-20240414233406890](assets/image-20240414233406890.png)

重启服务，执行测试代码 成功读取到最新消息

![image-20240414233445515](assets/image-20240414233445515.png)

#### 4.14.2 @Header注解：标记该参数是消息头内容

消费者类参数添加@Header注解 获取header中的topic和partition

```java
@Component
public class EventConsumer {

    // 采用监听的方式接收事件（消息、数据）
    @KafkaListener(topics = {"helloTopic"}, groupId = "helloGroup")
    public void onEvent(@Payload String event,
                        @Header(value = KafkaHeaders.RECEIVED_TOPIC) String topic,
                        @Header(value = KafkaHeaders.RECEIVED_PARTITION) String partition
                        ){
        System.out.println("读取到的事件：" + event +  ", topic:" + topic + ", partition:" + partition);
    }
}

```

重启服务类，测试代码不变，进行测试

![image-20240417231252270](assets/image-20240417231252270.png)

#### 4.14.3 ConsumerRecord对象

可以从ConsumerRecord对象中获取想要的内容

```java
@Component
public class EventConsumer {

    // 采用监听的方式接收事件（消息、数据）
    @KafkaListener(topics = {"helloTopic"}, groupId = "helloGroup")
    public void onEvent(@Payload String event,
                        @Header(value = KafkaHeaders.RECEIVED_TOPIC) String topic,
                        @Header(value = KafkaHeaders.RECEIVED_PARTITION) String partition,
                        ConsumerRecord<String, String> consumerRecord
                        ){
        System.out.println("读取到的事件：" + event +  ", topic:" + topic + ", partition:" + partition);
        System.out.println("读取到的consumerRecord：" + consumerRecord.toString());
    }
}
```

重启服务类，测试代码不变，进行测试

想要的内容都可以从ConsumerRecord对象中获取

![image-20240417231958706](assets/image-20240417231958706.png)

#### 4.14.4 获取对象类型数据

User类代码

```java
package com.zzc.model;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.Date;

@Builder
@AllArgsConstructor
@NoArgsConstructor
@Data
public class User {

    private int id;

    private String phone;

    private Date birthDay;
}

```



EventConsumer类新增onEvent2方法

```java
    @KafkaListener(topics = {"helloTopic"}, groupId = "helloGroup")
    public void onEvent2(User user,
                         @Header(value = KafkaHeaders.RECEIVED_TOPIC) String topic,
                         @Header(value = KafkaHeaders.RECEIVED_PARTITION) String partition,
                         ConsumerRecord<String, String> consumerRecord
                        ){
        System.out.println("读取到的事件：" + user +  ", topic:" + topic + ", partition:" + partition);
        System.out.println("读取到的consumerRecord：" + consumerRecord.toString());
    }
```

EventProducer类新增sendEvent2方法

```java
    @Resource
    private KafkaTemplate<String, Object> kafkaTemplate2;
    public void sendEvent2(){
        User user = User.builder().id(213234).phone("13239407234").birthDay(new Date()).build();
        kafkaTemplate2.send("helloTopic", user);
    }
```

测试类新增test02方法

```java
    @Test
    public void test02(){
        eventProducer.sendEvent2();
    }
```

执行测试，报错生产者不能将User转换成String类型

![image-20240417233435029](assets/image-20240417233435029.png)

去配置文件中修改生产者和消费者的value序列化器

```yaml
spring:
  application:
    name: spring-boot-02-kafka-base

  kafka:
    bootstrap-servers: 192.168.2.118:9092

    producer:
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

    consumer:
      value-deserializer: org.springframework.kafka.support.seri
```

重新启动服务，依然报错，说没有找到jackson的jar包

![image-20240417234207707](assets/image-20240417234207707.png)

那我们去pom文件中添加jackson依赖

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-json</artifactId>
</dependency>
```

添加依赖后可以正常启动了

![image-20240417234508055](assets/image-20240417234508055.png)

执行测试代码，服务一直报错，说User类不受安全的，只有java.util, java.lang下的类才是安全的

![image-20240417234750351](assets/image-20240417234750351.png)

解决方案：将对象类型转为String类型进行发送，读取的时候再将String类型转为对象类型

创建JSONUtils类

```java
package com.zzc.util;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;

public class JSONUtils {

    private static final ObjectMapper OBJECTMAPPER = new ObjectMapper();

    public static String toJSON(Object object){
        try {
            return OBJECTMAPPER.writeValueAsString(object);
        }catch (JsonProcessingException e){
            throw new RuntimeException(e);
        }
    }

    public static <T> T toBean(String jsonStr, Class<T> clazz){
        try {
            return OBJECTMAPPER.readValue(jsonStr, clazz);
        } catch (JsonProcessingException e) {
            throw new RuntimeException(e);
        }
    }
}

```

修改EventProducer代码，将原本的User类型改为String类型发送到topic中

```java
	public void sendEvent2(){
        User user = User.builder().id(213234).phone("13239407234").birthDay(new Date()).build();
        String userJson = JSONUtils.toJSON(user);
        kafkaTemplate.send("helloTopic", userJson);
    }
```

修改EventConsumer代码，将原本中参数的User类型改为String类型，再转换成User类型进行消费

```java
    @KafkaListener(topics = {"helloTopic"}, groupId = "helloGroup")
    public void onEvent2(String userStr,
                         @Header(value = KafkaHeaders.RECEIVED_TOPIC) String topic,
                         @Header(value = KafkaHeaders.RECEIVED_PARTITION) String partition,
                         ConsumerRecord<String, String> consumerRecord
    ){
        User user = (User) JSONUtils.toBean(userStr, User.class);
        System.out.println("读取到的事件：" + user +  ", topic:" + topic + ", partition:" + partition);
        System.out.println("读取到的consumerRecord：" + consumerRecord.toString());
    }
```

将配置文件中的消费者和生产者配置都注释掉

```java
spring:
  application:
    name: spring-boot-02-kafka-base

  kafka:
    bootstrap-servers: 192.168.2.118:9092

#    producer:
#      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

#    consumer:
#      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
```

重启服务，再次执行测试代码

![image-20240418224923719](assets/image-20240418224923719.png)



#### 4.14.5 获取自定义配置参数的数据

自定义配置topic的name和consumer的group值，消费者进行读取

```yaml
spring:
  application:
    name: spring-boot-02-kafka-base

  kafka:
    bootstrap-servers: 192.168.2.118:9092

#    producer:
#      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

#    consumer:
#      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer

kafka:
  topic:
    name: helloTopic
  consumer:
    group: helloGroup
```

使用${}的方式进行读取配置文件中的值

```java
    @KafkaListener(topics = {"${kafka.topic.name}"}, groupId = "kafka.consumer.group")
    public void onEvent3(String userStr,
                         @Header(value = KafkaHeaders.RECEIVED_TOPIC) String topic,
                         @Header(value = KafkaHeaders.RECEIVED_PARTITION) String partition,
                         ConsumerRecord<String, String> consumerRecord
    ){
        User user = (User) JSONUtils.toBean(userStr, User.class);
        System.out.println("读取到的事件3：" + user +  ", topic:" + topic + ", partition:" + partition);
        System.out.println("读取到的consumerRecord3：" + consumerRecord.toString());
    }
```

重启服务，执行测试代码，能够读取到消息

![image-20240418225855868](assets/image-20240418225855868.png)

#### 4.14.6 ACK手动确认消息

​		默认情况下， Kafka 消费者消费消息后会自动发送确认信息给 Kafka 服务器，表示消息已经被成功消费。但在
某些场景下，我们希望在消息处理成功后再发送确认，或者在消息处理失败时选择不发送确认，以便 Kafka 能
够重新发送该消息；

EventConsumer类代码

```java
    @KafkaListener(topics = {"${kafka.topic.name}"}, groupId = "kafka.consumer.group")
    public void onEvent4(String userStr,
                         @Header(value = KafkaHeaders.RECEIVED_TOPIC) String topic,
                         @Header(value = KafkaHeaders.RECEIVED_PARTITION) String partition,
                         ConsumerRecord<String, String> consumerRecord,
                         Acknowledgment acknowledgment
    ){
        User user = (User) JSONUtils.toBean(userStr, User.class);
        System.out.println("读取到的事件4：" + user +  ", topic:" + topic + ", partition:" + partition);
        System.out.println("读取到的consumerRecord4：" + consumerRecord.toString());

    }
```

配置文件中添加手动ack模式

```yaml
  kafka:
    bootstrap-servers: 192.168.2.118:9092
    listener:
      ack-mode: manual
```

重启服务，执行测试代码。无论重启多少此服务，都能读取到这条消息，因为还没有确认消费这条消息，所以offset一直没有变

![image-20240418231732865](assets/image-20240418231732865.png)

如果在代码中加入确认消费的话，那么就只会读取一次，offset也会发生变化

![image-20240418231930059](assets/image-20240418231930059.png)

重启服务后，不再读取到这条消息了

![image-20240418232003258](assets/image-20240418232003258.png)

平常业务中可以这么写

```java
    @KafkaListener(topics = {"${kafka.topic.name}"}, groupId = "kafka.consumer.group")
    public void onEvent4(String userStr,
                         @Header(value = KafkaHeaders.RECEIVED_TOPIC) String topic,
                         @Header(value = KafkaHeaders.RECEIVED_PARTITION) String partition,
                         ConsumerRecord<String, String> consumerRecord,
                         Acknowledgment acknowledgment
    ){
        try {
            User user = (User) JSONUtils.toBean(userStr, User.class);
            System.out.println("读取到的事件4：" + user +  ", topic:" + topic + ", partition:" + partition);
            System.out.println("读取到的consumerRecord4：" + consumerRecord.toString());
            int i = 1 / 0;
            // 可以执行完所有业务，再进行确认消息。如果执行过程中发生异常，那么可以再次消费此消息
            acknowledgment.acknowledge();
        }catch (Exception e){
            e.printStackTrace();
        }
    }
```

#### 4.14.7 指定 topic 、 partition 、 offset 消费

创建配置类，指定生成5个分区

```java
@Configuration
public class KafkaConfig {

    // 创建一个名为helloTopic的Topic并设置分区数为5，分区副本数为1
    @Bean
    public NewTopic newTopic(){
        return new NewTopic("helloTopic", 5, (short) 1);
    }

}

```

EventConsumer类中新增onEvent5方法

```java
 @KafkaListener(groupId = "${kafka.consumer.group}",
                	// 配置更加详细的监听信息 topics和topicPartitions不能同时使用
                    topicPartitions = {
                        @TopicPartition(
                                topic = "${kafka.topic.name}",
                            	// 监听topic的0、1、2号分区的所有消息
                                partitions = {"0", "1", "2"},
                            	// 监听3、4号分区中offset从3开始的消息
                                partitionOffsets = {
                                        @PartitionOffset(partition = "3", initialOffset = "3"),
                                        @PartitionOffset(partition = "4", initialOffset = "3")
                                }
                        )
                    })
    public void onEvent5(String userStr,
                         @Header(value = KafkaHeaders.RECEIVED_TOPIC) String topic,
                         @Header(value = KafkaHeaders.RECEIVED_PARTITION) String partition,
                         ConsumerRecord<String, String> consumerRecord,
                         Acknowledgment acknowledgment
    ){
        try {
            User user = (User) JSONUtils.toBean(userStr, User.class);
            System.out.println("读取到的事件5：" + user +  ", topic:" + topic + ", partition:" + partition);
            System.out.println("读取到的consumerRecord5：" + consumerRecord.toString());
            acknowledgment.acknowledge();
        }catch (Exception e){
            e.printStackTrace();
        }
    }
```

EventProducer新增sendEvent3方法

```java
    public void sendEvent3(){
        for (int i = 0; i < 25; i++) {
            User user = User.builder().id(i).phone("13239407234" + i).birthDay(new Date()).build();
            String userJson = JSONUtils.toJSON(user);
            kafkaTemplate2.send("helloTopic", "k" + i, userJson);
        }

    }
```

重启服务，执行测试代码

```java
    @Test
    public void test03(){
        eventProducer.sendEvent3();
    }
```

生成的25个消息已经发送到0~4号分区里了

![image-20240418234511931](assets/image-20240418234511931.png)

消费消息，**注意：需要停止服务，先运行测试代码，再启动服务**

发现只消费了3条消息

![image-20240420195655830](assets/image-20240420195655830.png)

![image-20240420195917568](assets/image-20240420195917568.png)

现在去配置文件中修改成从最早的消息开始消费

```yaml
    consumer:
      # 从最早的消息开始消费
      auto-offset-reset: earliest
```

再次重启服务进行消费，发现还是只消费到3条消息

![image-20240420200325644](assets/image-20240420200325644.png)

这是怎么回事呢？我们之前有遇到过这种情况，有两个解决方案

- 手动修改分区的偏移量
- 换一个消费组id

我们去配置文件中换一个groupId，由原来的helloGroup改为helloGroup1

![image-20240420200536770](assets/image-20240420200536770.png)

再次重启服务，发现已经读取到19个消息了

![image-20240420200755543](assets/image-20240420200755543.png)

![image-20240420201001537](assets/image-20240420201001537.png)

再次重启服务的话，发现又只能消费3个消息了

![image-20240420201049363](assets/image-20240420201049363.png)



#### 4.14.8  批量消费消息

重新创建一个模块 spring-boot-03-kafka-base

配置文件进行批量消费配置

```yaml
spring:
  application:
    name: spring-boot-03-kafka-base

  kafka:
    bootstrap-servers: 192.168.2.118:9092
    consumer:
      # 设置批量最多消费多少条消息
      max-poll-records: 20

    listener:
      # 设置批量消费
      type: batch
```

创建EventConsumer类

```java
package com.zzc.springboot03kafkabase.cosumer;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

import java.util.List;

@Component
public class EventConsumer {

    @KafkaListener(topics = "batchTopic", groupId = "bactchGroup")
    public void onEvent(List<ConsumerRecord<String, String>> records) {
        System.out.println(" 批量消费， records.size() = " + records.size() + " ， records = " + records);
    }
}

```

User类

```java
package com.zzc.springboot03kafkabase.model;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.Date;

@Builder
@AllArgsConstructor
@NoArgsConstructor
@Data
public class User {

    private int id;

    private String phone;

    private Date birthDay;
}

```

创建EventProducer类

```java
package com.zzc.springboot03kafkabase.producer;

import com.zzc.springboot03kafkabase.model.User;
import com.zzc.springboot03kafkabase.util.JSONUtils;
import jakarta.annotation.Resource;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

import java.util.Date;

@Component
public class EventProducer {

    @Resource
    private KafkaTemplate<String, String> kafkaTemplate;

    public void sendEvent(){
        for (int i = 0; i < 125; i++) {
            User user = User.builder().id(i).phone("13239407234" + i).birthDay(new Date()).build();
            String userJson = JSONUtils.toJSON(user);
            kafkaTemplate.send("batchTopic", "k" + i, userJson);
        }
    }


}
```

创建Json字符串转换对象工具类

```java
package com.zzc.springboot03kafkabase.util;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;

public class JSONUtils {

    private static final ObjectMapper OBJECTMAPPER = new ObjectMapper();

    public static String toJSON(Object object){
        try {
            return OBJECTMAPPER.writeValueAsString(object);
        }catch (JsonProcessingException e){
            throw new RuntimeException(e);
        }
    }

    public static <T> T toBean(String jsonStr, Class<T> clazz){
        try {
            return OBJECTMAPPER.readValue(jsonStr, clazz);
        } catch (JsonProcessingException e) {
            throw new RuntimeException(e);
        }
    }
}

```

pom文件

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>3.2.5</version>
        <relativePath/> <!-- lookup parent from repository -->
    </parent>
    <groupId>com.zzc</groupId>
    <artifactId>spring-boot-03-kafka-base</artifactId>
    <version>0.0.1-SNAPSHOT</version>
    <name>spring-boot-03-kafka-base</name>
    <description>spring-boot-03-kafka-base</description>
    <properties>
        <java.version>17</java.version>
    </properties>
    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-json</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-devtools</artifactId>
            <scope>runtime</scope>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
            <optional>true</optional>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka-test</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
                <configuration>
                    <excludes>
                        <exclude>
                            <groupId>org.projectlombok</groupId>
                            <artifactId>lombok</artifactId>
                        </exclude>
                    </excludes>
                </configuration>
            </plugin>
        </plugins>
    </build>

</project>

```

先执行测试文件，生成125个消息到batchTopic的主题中

![image-20240420203816942](assets/image-20240420203816942.png)

启动服务，发现一条消息也没有消费到

![image-20240420204352540](assets/image-20240420204352540.png)

这个问题之前也遇到过，因为默认是最后一个偏移量+1开始消费的。

此时我们需要先在配置文件中将消费消息配置成从最早消息开始消费

```yaml
    consumer:
      # 设置批量最多消费多少条消息
      max-poll-records: 20
      auto-offset-reset: earliest
```

修改groupId，因为之前已经使用这个groupId消费过次一次了 所以要换一个groupId

![image-20240420205033716](assets/image-20240420205033716.png)

重启服务，成功消费到消息。每次最多消费20条，总共125条消息都消费到了。

![image-20240420205133087](assets/image-20240420205133087.png)



### 4.15 消费消息拦截器

​		在消息消费之前，我们可以通过配置拦截器对消息进行拦截，在消息被实际处理之前对其进行一些操作，例如记录日志、修改消息内容或执行一些安全检查等；

#### 4.15.1 创建新模块spring-boot-04-kafka-base，依赖还是springboot、Lombok、kafka这三个

#### 4.15.2 主文件中添加代码

```java
package com.zzc;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.ApplicationContext;
import org.springframework.context.ConfigurableApplicationContext;
import org.springframework.kafka.config.KafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;

import java.util.Map;

@SpringBootApplication
public class SpringBoot04KafkaBaseApplication {

    public static void main(String[] args) {
        ApplicationContext context = SpringApplication.run(SpringBoot04KafkaBaseApplication.class, args);
        Map<String, ConsumerFactory> beansOfType = context.getBeansOfType(ConsumerFactory.class);
        beansOfType.forEach((k, v) -> {
            System.out.println(k + " -- " + v);
        });

        Map<String, KafkaListenerContainerFactory> beansOfType2 = context.getBeansOfType(KafkaListenerContainerFactory.class);
        beansOfType2.forEach((k, v) -> {
            System.out.println(k + " -- " + v);
        });
    }

}

```

启动服务类，发现容器中默认有kafkaConsumerFactory和kafkaListenerContainerFactory类

![image-20240421115650923](assets/image-20240421115650923.png)

**我们需要使用自己的kafkaConsumerFactory和kafkaListenerContainerFactory，因为我们需要加上拦截器**

#### 4.15.2 创建拦截器CustomConsumerInterceptor

```java
package com.zzc.interceptor;


import org.apache.kafka.clients.consumer.ConsumerInterceptor;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.common.TopicPartition;

import java.util.Map;

public class CustomConsumerInterceptor implements ConsumerInterceptor<String, String > {

    /**
     * 在消费消息之前执行
     * @param consumerRecords
     * @return
     */
    @Override
    public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> consumerRecords) {
        System.out.println("onConsumer方法执行：" + consumerRecords);
        return consumerRecords;
    }

    /**
     * 消息拿到之后，提交offset之前执行该方法
     * @param offsets
     */
    @Override
    public void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets) {
        System.out.println("onCommit方法执行：" + offsets);
    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> map) {

    }
}

```

#### 4.15.3 创建配置类

```java
package com.zzc.config;

import com.zzc.interceptor.CustomConsumerInterceptor;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.config.KafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaConfig {



    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Value("${spring.kafka.consumer.value-deserializer}")
    private String valueDeSerializer;

    @Value("${spring.kafka.consumer.key-deserializer}")
    private String keyDeSerializer;


    public Map<String, Object> consumerConfigs(){
        HashMap<String, Object> consumer = new HashMap<>();
        consumer.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,bootstrapServers);
        consumer.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,keyDeSerializer);
        consumer.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, valueDeSerializer);
        // 添加一个消费拦截器
        consumer.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, CustomConsumerInterceptor.class.getName());
        return consumer;
    }

    /**
     * 消费者创建工厂
     * @return
     */
    @Bean
    public ConsumerFactory<String, String> ourConsumerFactory(){
        return new DefaultKafkaConsumerFactory<>(consumerConfigs());
    }

    /**
     * 监听器容器工厂
     * @param ourConsumerFactory
     * @return
     */
    @Bean
    public KafkaListenerContainerFactory ourKafkaListenerContainerFactory(ConsumerFactory ourConsumerFactory){
        ConcurrentKafkaListenerContainerFactory<String, String> listenerContainerFactory = new ConcurrentKafkaListenerContainerFactory<>();
        listenerContainerFactory.setConsumerFactory(ourConsumerFactory);
        return listenerContainerFactory;
    }
}

```

#### 4.15.4 测试spring容器默认的和自定义的消费者创建工厂和监听器容器工厂

重启服务，测试容器中用的已经是我们自己创建的消费者创建工厂和监听器容器工厂了

![image-20240421120355259](assets/image-20240421120355259.png)

我们自定义的监听器容器工厂的配置中可以看到有我们创建的拦截器对象

![image-20240421120541038](assets/image-20240421120541038.png)

spring的默认监听器工厂对象的配置中就没有我们创建的拦截器对象

![image-20240421120650994](assets/image-20240421120650994.png)

#### 4.15.5 消费消息

创建消费者对象，KafkaListener注解加上containerFactory参数

```java
package com.zzc.cosumer;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

import java.util.List;

@Component
public class EventConsumer {

    @KafkaListener(topics = {"interTopic"}, groupId = "interGroup", containerFactory = "ourKafkaListenerContainerFactory")
    public void onEvent(ConsumerRecord<String, String> records) {
        System.out.println(" 消费消息， records = " + records);
    }
}
```

创建生产者对象

```java
package com.zzc.producer;


import com.zzc.model.User;
import com.zzc.util.JSONUtils;
import jakarta.annotation.Resource;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

import java.util.Date;

@Component
public class EventProducer {

    @Resource
    private KafkaTemplate<String, String> kafkaTemplate;

    public void sendEvent() {
        User user = User.builder().id(1023).phone("13239407234").birthDay(new Date()).build();
        String userJson = JSONUtils.toJSON(user);
        kafkaTemplate.send("interTopic", "k", userJson);
    }


}
```

测试代码

```java
    @Resource
    private EventProducer eventProducer;

    @Test
    public void test(){
        eventProducer.sendEvent();
    }
```

启动服务，再执行测试代码，成功打印出拦截器中的消息

![image-20240421145158993](assets/image-20240421145158993.png)

测试KafkaListener注解中不加containerFactory参数是否会打印拦截器的消息

```java
@Component
public class EventConsumer {

//    @KafkaListener(topics = {"interTopic"}, groupId = "interGroup", containerFactory = "ourKafkaListenerContainerFactory")
    @KafkaListener(topics = {"interTopic"}, groupId = "interGroup", )
    public void onEvent(ConsumerRecord<String, String> records) {
        System.out.println(" 消费消息， records = " + records);
    }
}

```

重启服务，再次执行测试代码，发现并没有打印出拦截器的消息

![image-20240421145846045](assets/image-20240421145846045.png)

### 4.16 消息转发

​		消息转发就是应用 A 从 TopicA 接收到消息，经过处理后转发到 TopicB ，再由应用 B 监听接收该消息，即一个应用处理完成后将该消息转发至其他应用处理，这在实际开发中，是可能存在这样的需求的；

**创建一个新模块spring-boot-05-kafka-base，结构如下**

![image-20240421152521187](assets/image-20240421152521187.png)

consumer代码

```java
package com.zzc.cosumer;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.messaging.handler.annotation.SendTo;
import org.springframework.stereotype.Component;

import java.util.List;

@Component
public class EventConsumer {

    @KafkaListener(topics = {"topicA"}, groupId = "group1")
    @SendTo("topicB")  // 转发消息给topicB
    public String onEvent(ConsumerRecord<String, String> record) {
        System.out.println(" 消费消息， record = " + record);
        return record.value() + "forward message";
    }

    @KafkaListener(topics = {"topicB"}, groupId = "group2")
    public void onEvent2(List<ConsumerRecord<String, String>> records) {
        System.out.println(" 消费消息， record = " + records);
    }
}

```

producer代码

```java
package com.zzc.producer;


import com.zzc.model.User;
import com.zzc.util.JSONUtils;
import jakarta.annotation.Resource;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

import java.util.Date;

@Component
public class EventProducer {

    @Resource
    private KafkaTemplate<String, String> kafkaTemplate;

    public void sendEvent() {
        User user = User.builder().id(1023).phone("13239407234").birthDay(new Date()).build();
        String userJson = JSONUtils.toJSON(user);
        kafkaTemplate.send("topicA", "k", userJson);
    }
}
```

启动服务，执行测试代码

![image-20240421152743561](assets/image-20240421152743561.png)

![image-20240421152901284](assets/image-20240421152901284.png)

### 4.17 消息消费的分区策略

- Kafka 消费消息时的分区策略：是指 Kafka 主题 topic 中哪些分区应该由哪些消费者来消费；

![image-20240421152948683](assets/image-20240421152948683.png)

- Kafka 有多种分区分配策略，默认的分区分配策略是RangeAssignor ，除了 RangeAssignor 策略外， Kafka 还有其他分区分配策略：	
  - RoundRobinAssignor 
  - StickyAssignor
  - CooperativeStickyAssignor ，
- 这些策略各有特点，可以根据实际的应用场景和需求来选择适合的分区分配策略；

![image-20240421153059247](assets/image-20240421153059247.png)

#### 4.17.1 RangeAssignor 策略

创建新模块spring-boot-06-kafka-base

配置类KafkaConfig

```java
package com.zzc.config;

import org.apache.kafka.clients.admin.NewTopic;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class KafkaConfig {


    // 创建一个名为helloTopic的Topic并设置分区数为5，分区副本数为1
    @Bean
    public NewTopic newTopic(){
        return new NewTopic("myTopic", 10, (short) 1);
    }
}

```

消费者类EventConsumer

```java
package com.zzc.cosumer;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

import java.util.List;

@Component
public class EventConsumer {

    // concurrency 消费者数量
    @KafkaListener(topics = {"myTopic"}, groupId = "myGroup", concurrency = "3")
    public void onEvent(ConsumerRecord<String, String> records) {
        System.out.println(" 消费消息， records = " + records);
    }
}

```

生产者类

```java
package com.zzc.producer;


import com.zzc.model.User;
import com.zzc.util.JSONUtils;
import jakarta.annotation.Resource;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

import java.util.Date;

@Component
public class EventProducer {

    @Resource
    private KafkaTemplate<String, String> kafkaTemplate;

    public void sendEvent() {
        for (int i = 0; i < 100; i++) {
            User user = User.builder().id(i).phone("13239407234" + i).birthDay(new Date()).build();
            String userJson = JSONUtils.toJSON(user);
            kafkaTemplate.send("myTopic", "k" + i, userJson);
        }

    }


}
```

测试代码

```java
package com.zzc;

import com.zzc.producer.EventProducer;
import jakarta.annotation.Resource;
import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;

@SpringBootTest
class SpringBoot06KafkaBaseApplicationTests {

    @Resource
    private EventProducer eventProducer;

    @Test
    public void test(){
        eventProducer.sendEvent();
    }

}

```

配置文件

```yaml
spring:
  application:
    name: spring-boot-06-kafka-base


  kafka:
    bootstrap-servers: 192.168.2.118:9092

    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest
```



先执行测试代码，生产100个消息发送到10个分区中

![image-20240421164114326](assets/image-20240421164114326.png)

启动服务，进行消费，打印出100个消息

![image-20240421164351933](assets/image-20240421164351933.png)

我们来看一下最小的线程id38是否消费4个分区

![image-20240421164605270](assets/image-20240421164605270.png)

![image-20240421164620937](assets/image-20240421164620937.png)

线程id38确实是消费了0、1、2、3号共4个分区。其他两个线程各消费3个分区



#### 4.17.2 RoundRobinAssignor策略

配置文件中无法修改策略，所以需要在配置类中设置

配置类代码

```java
package com.zzc.config;

import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.RoundRobinAssignor;
import org.apache.kafka.clients.producer.RoundRobinPartitioner;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.config.KafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Value("${spring.kafka.consumer.value-deserializer}")
    private String valueDeSerializer;

    @Value("${spring.kafka.consumer.key-deserializer}")
    private String keyDeSerializer;

    @Value("${spring.kafka.consumer.auto-offset-reset}")
    private String autoOffsetReset;


    public Map<String, Object> consumerConfigs(){
        HashMap<String, Object> consumer = new HashMap<>();
        consumer.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,bootstrapServers);
        consumer.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,keyDeSerializer);
        consumer.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, valueDeSerializer);
        consumer.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, autoOffsetReset);
        // 设置消费者策略为轮询模式
        consumer.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, RoundRobinAssignor.class.getName());

        return consumer;
    }


    // 创建一个名为helloTopic的Topic并设置分区数为5，分区副本数为1
    @Bean
    public NewTopic newTopic(){
        return new NewTopic("myTopic", 10, (short) 1);
    }

    /**
     * 消费者创建工厂
     * @return
     */
    @Bean
    public ConsumerFactory<String, String> ourConsumerFactory(){
        return new DefaultKafkaConsumerFactory<>(consumerConfigs());
    }

    /**
     * 监听器容器工厂
     * @param ourConsumerFactory
     * @return
     */
    @Bean
    public KafkaListenerContainerFactory ourKafkaListenerContainerFactory(ConsumerFactory ourConsumerFactory){
        ConcurrentKafkaListenerContainerFactory<String, String> listenerContainerFactory = new ConcurrentKafkaListenerContainerFactory<>();
        listenerContainerFactory.setConsumerFactory(ourConsumerFactory);
        return listenerContainerFactory;
    }
}

```

消费者代码中设置为自定义监听器容器创建工厂

```java
package com.zzc.cosumer;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

import java.util.List;

@Component
public class EventConsumer {

    // concurrency 设置消费者数量    containerFactory 设置监听器容器工厂
    @KafkaListener(topics = {"myTopic"}, groupId = "myGroup4", concurrency = "3", containerFactory = "ourKafkaListenerContainerFactory")
    public void onEvent(ConsumerRecord<String, String> records) {
        System.out.println(Thread.currentThread().getId() + " --> 消费消息， records = " + records);
    }
}

```

执行测试代码，发现线程id39消费的分区变成0、3、6、9号分区了

![image-20240421171518854](assets/image-20240421171518854.png)

![image-20240421171550231](assets/image-20240421171550231.png)

**采用 RoundRobinAssignor 策略进行测试，得到的结果如下：**
39 ： 0 ， 3 ， 6 ， 9
41 ： 1 ， 4 ， 7
43 ： 2 ， 5 ， 8

#### 4.17.3 StickyAssignor 消费分区策略

- 尽可能保持消费者与分区之间的分配关系不变，即使消费组的消费者成员发生变化，减少不必要的分区重分配；
- 尽量保持现有的分区分配不变，仅对新加入的消费者或离开的消费者进行分区调整。这样，大多数消费者可以
  继续消费它们之前消费的分区，只有少数消费者需要处理额外的分区；所以叫“粘性”分配；

#### 4.17.4 CooperativeStickyAssignor 消费分区策略

- 与 StickyAssignor 类似，但增加了对协作式重新平衡的支持，即消费者可以在它离开消费者组之前通知协调
  器，以便协调器可以预先计划分区迁移，而不是在消费者突然离开时立即进行分区重分配；



### 4.18 Kafka 事件 ( 消息、数据 ) 的存储

- kafka的所有事件（消息、数据）都存储在/tmp/kafka-logs目录中，可通过log.dirs=/tmp/kafka-logs配置

- Kafka的所有事件（消息、数据）都是以日志文件的方式来保存

- Kafka一般都是海量的消息数据，为了避免日志文件过大，日志文件被存放在多个日志目录下，日志目录的命名规则为：<topic_name>-<partiton_id>

- 比如创建一个名为 firstTopic 的 topic ，其中有 3 个 partition ，那么在 kafka 的数据目录（ /tmp/kafka-
  log ）中就有 3 个目录， firstTopic-0 、 firstTopic-1 、 firstTopic-2 ；

  ![image-20240421174048514](assets/image-20240421174048514.png)

​		进入myTopic-0中

![image-20240421174146829](assets/image-20240421174146829.png)

查看日志信息

![image-20240421174224302](assets/image-20240421174224302.png)

- 00000000000000000000.index 消息索引文件
- 00000000000000000000.log 消息数据文件
- 00000000000000000000.timeindex 消息的时间戳索引文件
- 00000000000000000006.snapshot 快照文件，生产者发生故障或重启时能够恢复并继续之前的操作
- leader-epoch-checkpoint 记录每个分区当前领导者的 epoch 以及领导者开始写入消息时的起始偏移量
- partition.metadata 存储关于特定分区的元数据（ metadata ）信息

```tex
 每次消费一个消息并且提交以后，会保存当前消费到的最近的一个 offset ；
 在 kafka 中，有一个 __consumer_offsets 的 topic ， 消费者消费提交的 offset 信息会写入到
该 topic 中， __consumer_offsets 保存了每个 consumer group 某一时刻提交的 offset 信息
， __consumer_offsets 默认有 50 个分区；
 consumer_group 保存在哪个分区中的计算公式：
 Math.abs(“groupid”.hashCode())%groupMetadataTopicPartitionCount ;
```

### 4.19 Offset详解

#### 4.19.1 生产者Offset

- 生产者发送一条消息到 Kafka 的 broker 的某个 topic 下某个 partition 中；

- Kafka 内部会为每条消息分配一个唯一的 offset ，该 offset 就是该消息在 partition 中的位置

  ![image-20240421184523180](assets/image-20240421184523180.png)

![image-20240421184537427](assets/image-20240421184537427.png)

创建spring-boot-07-kafka-base模块

消费者代码

```java
package com.zzc.cosumer;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

@Component
public class EventConsumer {


    @KafkaListener(topics = {"offsetTopic"}, groupId = "offsetGroup")
    public void onEvent(ConsumerRecord<String, String> records) {
        System.out.println(Thread.currentThread().getId() + " --> 消费消息， records = " + records);
    }
}

```

生产者代码

```java
package com.zzc.producer;


import com.zzc.model.User;
import com.zzc.util.JSONUtils;
import jakarta.annotation.Resource;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

import java.util.Date;

@Component
public class EventProducer {

    @Resource
    private KafkaTemplate<String, String> kafkaTemplate;

    public void sendEvent() {
        for (int i = 0; i < 2; i++) {
            User user = User.builder().id(i).phone("13239407234" + i).birthDay(new Date()).build();
            String userJson = JSONUtils.toJSON(user);
            kafkaTemplate.send("offsetTopic", "k" + i, userJson);
        }

    }


}
```

配置文件

```yaml
spring:
  application:
    name: spring-boot-07-kafka-base


  kafka:
    bootstrap-servers: 192.168.2.118:9092

    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
```

测试代码

```java
package com.zzc;

import com.zzc.producer.EventProducer;
import jakarta.annotation.Resource;
import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;

@SpringBootTest
class SpringBoot07KafkaBaseApplicationTests {

    @Resource
    private EventProducer eventProducer;

    @Test
    public void test(){
        eventProducer.sendEvent();
    }

}

```

执行测试代码

![image-20240421192921764](assets/image-20240421192921764.png)



#### 4.19.2 消费者Offset

1. 每个消费者组启动开始监听消息，默认从消息的最新的位置开始监听消息，即把最新的位置作为消费者
   offset ；
   - 分区中还没有发送消息，则最新的位置就是0
   - 分区中已经发送过消息，则最新的位置就是生产者offset的下一个位置
2. 消费者消费消息后，如果不提交确认（ ack ），则 offset 不更新，提交了才更新；

- 命令行命令： ./kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --group 消费者组名 --describe

##### 4.19.2.1 验证分区中已经发送过消息的情况

启动服务，监听器并没有消费到消息

![image-20240421193954155](assets/image-20240421193954155.png)

使用命令看一下offsetGroup的offset是在哪

![image-20240421194257796](assets/image-20240421194257796.png)

**我们再发两条消息试试，先把服务停了，执行测试代码发送消息**

再次执行命令 查看offsetGroup的offset是在哪

![image-20240421194457316](assets/image-20240421194457316.png)

我们现在启动服务，能够消费到消息了

![image-20240421194540229](assets/image-20240421194540229.png)

消费完消息，再次执行命令，发现current-offset已经变成4了，也没有消息可读了

![image-20240421194639429](assets/image-20240421194639429.png)

##### 4.19.2.2 验证分区中还没有发过消息的情况

我们把offsetTopic删除，然后重启服务，再执行命令

![image-20240421195217048](assets/image-20240421195217048.png)然后停止服务，执行测试代码 发送消息，在执行命令

![image-20240421195413022](assets/image-20240421195413022.png)

我们再启动服务，就能够消费这2个消息

![image-20240421195502942](assets/image-20240421195502942.png)



#### 4.19.3 offset总结

​		**消费者从什么位置开始消费，就看消费者的 offset 是多少，消费者 offset 是多少，它启动后，可以通过上面**
**的命令查看；**

